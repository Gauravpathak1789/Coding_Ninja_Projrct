{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ee0a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal,Annotated\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph,MessagesState,START,END\n",
    "from langgraph.types import Command\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Image\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "from langchain_core.messages import HumanMessage,AIMessage,SystemMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from youtube_search import YoutubeSearch\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "import sqlite3\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph_supervisor import create_supervisor\n",
    "\n",
    "from langchain_community.utilities.semanticscholar import SemanticScholarAPIWrapper\n",
    "from langchain.schema import HumanMessage\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PyPDF2 import PdfReader\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled, VideoUnavailable\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100d1143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9bd005",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_model=ChatGroq(model=\"deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "871c1fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello World! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 37, 'total_tokens': 63}, 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--74e150be-88a8-478d-a36f-1f3a40902098-0', usage_metadata={'input_tokens': 37, 'output_tokens': 26, 'total_tokens': 63})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    do_sample=False,\n",
    "    top_p=1.0,\n",
    "    top_k=0,\n",
    "    provider=\"auto\"  # let Hugging Face choose the best provider for you\n",
    ")\n",
    "hf_model = ChatHuggingFace(llm=llm)\n",
    "hf_model.invoke([HumanMessage(content=\"Hello World\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4575fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"openai/gpt-oss-20b\",\n",
    "#     task=\"text-generation\",\n",
    "#     do_sample=False,\n",
    "#     top_p=1.0,\n",
    "#     top_k=0,\n",
    "#     provider=\"auto\",  # let Hugging Face choose the best provider for you\n",
    "# )\n",
    "\n",
    "# hf_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b99168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groq_model.invoke([HumanMessage(content=\"hii how are you?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbfc7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def youtube_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search YouTube for videos related to the query and return top 3 video links with titles.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    API_KEY = \"AIzaSyBNBTgze_5FR5VHzfZlxc38iLwr7xyYaHE\"\n",
    "    url = \"https://www.googleapis.com/youtube/v3/search\"\n",
    "    params = {\n",
    "        \"part\": \"snippet\",\n",
    "        \"q\": query,\n",
    "        \"type\": \"video\",\n",
    "        \"maxResults\": 3,\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "    res = requests.get(url, params=params).json()\n",
    "    items = res.get(\"items\", [])\n",
    "    videos = [\n",
    "        f\"{item['snippet']['title']} - https://www.youtube.com/watch?v={item['id']['videoId']}\"\n",
    "        for item in items if item.get('id', {}).get('videoId')\n",
    "    ]\n",
    "    if not videos:\n",
    "        return \"No related videos found.\"\n",
    "    return \"\\n\".join(videos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17a6d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def generate_resume(job_description: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a structured resume and cover letter based on the job description.\n",
    "    Returns output in clean, formatted HTML for easy display.\n",
    "    \"\"\"\n",
    "    \n",
    "    html_template = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; line-height: 1.5; }}\n",
    "            h2 {{ color: #2E86C1; }}\n",
    "            h3 {{ color: #117A65; }}\n",
    "            p {{ margin-bottom: 10px; }}\n",
    "            .section {{ margin-bottom: 20px; }}\n",
    "            .highlight {{ color: #D35400; font-weight: bold; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"section\">\n",
    "            <h2>üìÑ Resume - Tailored for: {job_description}</h2>\n",
    "            <h3>Summary</h3>\n",
    "            <p>Experienced professional with skills and expertise matching <span class=\"highlight\">{job_description}</span>. \n",
    "            Strong problem-solving abilities and a passion for excellence in the relevant field.</p>\n",
    "        </div>\n",
    "        <div class=\"section\">\n",
    "            <h3>Skills</h3>\n",
    "            <p>‚Ä¢ Core skills relevant to {job_description}<br>\n",
    "               ‚Ä¢ Additional complementary skills<br>\n",
    "               ‚Ä¢ Technical & soft skills</p>\n",
    "        </div>\n",
    "        <div class=\"section\">\n",
    "            <h3>Experience</h3>\n",
    "            <p>‚Ä¢ Previous roles and achievements tailored to {job_description}<br>\n",
    "               ‚Ä¢ Demonstrated impact and measurable results</p>\n",
    "        </div>\n",
    "        <div class=\"section\">\n",
    "            <h2>‚úâÔ∏è Cover Letter</h2>\n",
    "            <p>Dear Hiring Manager,</p>\n",
    "            <p>I am excited to apply for the <span class=\"highlight\">{job_description}</span> role. \n",
    "            With my background, skills, and passion for this field, I am confident in delivering impactful results. \n",
    "            I look forward to contributing to your team‚Äôs success.</p>\n",
    "            <p>Best regards,<br>Your Name</p>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return html_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ab75d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(url: str, max_pages: int = 5) -> str:\n",
    "    try:\n",
    "        response = requests.get(url, timeout=15)\n",
    "        if response.status_code != 200:\n",
    "            return \"\"\n",
    "        pdf_file = BytesIO(response.content)\n",
    "        reader = PdfReader(pdf_file)\n",
    "        text = [page.extract_text() or \"\" for page in reader.pages[:max_pages]]\n",
    "        return \"\\n\".join(text)\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting PDF: {e}\"\n",
    "\n",
    "# -------------------------\n",
    "# Initialize Semantic Scholar API\n",
    "# -------------------------\n",
    "ss = SemanticScholarAPIWrapper(\n",
    "    top_k_results=5,\n",
    "    load_max_docs=5\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Unified Semantic Scholar Tool\n",
    "# -------------------------\n",
    "@tool\n",
    "def semantic_scholar_research(query: str, summarize: bool = True) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch top research papers from Semantic Scholar for a query.\n",
    "    - Optionally summarize abstracts using LLM.\n",
    "    - Attempt PDF extraction if URL is provided.\n",
    "    \"\"\"\n",
    "    raw_results = ss.run(query)  # Returns string with paper info\n",
    "    papers = raw_results.split(\"\\n\\n\")\n",
    "    summarized_papers = []\n",
    "\n",
    "    for paper in papers:\n",
    "        summary = \"\"\n",
    "        pdf_summary = \"\"\n",
    "        # Summarize abstract\n",
    "        if summarize and \"abstract:\" in paper.lower():\n",
    "            prompt = f\"Summarize this research abstract in 2-3 sentences:\\n\\n{paper}\"\n",
    "            summary = hf_model.invoke([HumanMessage(content=prompt)]).content\n",
    "\n",
    "        # Attempt PDF extraction if a PDF link is in text\n",
    "        if \"http\" in paper and \".pdf\" in paper.lower():\n",
    "            pdf_url = paper.split(\"http\")[1].split()[0]\n",
    "            pdf_url = \"http\" + pdf_url\n",
    "            pdf_text = extract_text_from_pdf(pdf_url)\n",
    "            if pdf_text and summarize:\n",
    "                pdf_prompt = f\"Summarize this PDF content (first 500 words):\\n\\n{pdf_text[:3000]}\"\n",
    "                pdf_summary = hf_model.invoke([HumanMessage(content=pdf_prompt)]).content\n",
    "\n",
    "        summarized_papers.append({\n",
    "            \"raw_info\": paper,\n",
    "            \"summary\": summary,\n",
    "            \"pdf_summary\": pdf_summary\n",
    "        })\n",
    "\n",
    "    return summarized_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e84f6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Prompt Template\n",
    "# -----------------------------\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant designed to answer questions about a YouTube video link taht have been provided based on its transcript.\n",
    "Answer the user's question using ONLY the provided transcript context.\n",
    "If the information is not in the context, explicitly say \"I cannot find information about that in the video transcript.\"\n",
    "\n",
    "Transcript:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=['context', 'question'])\n",
    "\n",
    "# -----------------------------\n",
    "# Transcript Fetcher\n",
    "# -----------------------------\n",
    "def get_transcript(video_id: str):\n",
    "    \"\"\"Fetch transcript safely for old and new versions of youtube_transcript_api.\"\"\"\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi().fetch(video_id, languages=[\"hi\"])\n",
    "    except NoTranscriptFound:\n",
    "        try:\n",
    "            transcript_list = YouTubeTranscriptApi().fetch(video_id, languages=[\"en\"])\n",
    "        except NoTranscriptFound:\n",
    "            return None, \"No transcript available in Hindi or English.\"\n",
    "    except (TranscriptsDisabled, VideoUnavailable) as e:\n",
    "        return None, str(e)\n",
    "    except Exception as e:\n",
    "        return None, f\"Unexpected error: {str(e)}\"\n",
    "\n",
    "    # Handle both dicts and FetchedTranscriptSnippet objects\n",
    "    texts = []\n",
    "    for snippet in transcript_list:\n",
    "        if isinstance(snippet, dict):\n",
    "            texts.append(snippet.get(\"text\", \"\"))\n",
    "        else:\n",
    "            # FetchedTranscriptSnippet object\n",
    "            texts.append(getattr(snippet, \"text\", \"\"))\n",
    "\n",
    "    transcript = \" \".join(texts)\n",
    "    return transcript, None\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main YouTube QA / Summarizer\n",
    "# -----------------------------\n",
    "@tool\n",
    "def youtube_qa(video_url: str, question: str):\n",
    "    \"\"\"Given a YouTube URL and question, return answer based on transcript.\"\"\"\n",
    "    try:\n",
    "        video_id = video_url.split(\"v=\")[-1].split(\"&\")[0]  # Extract only the video ID\n",
    "        transcript, error = get_transcript(video_id)\n",
    "        if error:\n",
    "            return error\n",
    "\n",
    "        rag_runnable = (\n",
    "            {\"context\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | hf_model\n",
    "        )\n",
    "        answer = rag_runnable.invoke({\"context\": transcript, \"question\": question})\n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d017872",
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_tool = DuckDuckGoSearchRun()\n",
    "tavile_tool = TavilySearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18ff3380",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 656\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;66;03m# Example 1: curriculum-style query\u001b[39;00m\n\u001b[0;32m    655\u001b[0m     q1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate a resume and cover letter for a Software Engineer internship\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 656\u001b[0m     result1 \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork_app\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mq1\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m result1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    658\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Gaurav Pathak\\OneDrive\\Desktop\\Langgraph\\langvenv\\lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[0;32m   3023\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3024\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 3026\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   3027\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3028\u001b[0m     config,\n\u001b[0;32m   3029\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m   3030\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3032\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[0;32m   3033\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[0;32m   3034\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   3035\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   3036\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   3037\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[0;32m   3038\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3039\u001b[0m ):\n\u001b[0;32m   3040\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3041\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Gaurav Pathak\\OneDrive\\Desktop\\Langgraph\\langvenv\\lib\\site-packages\\langgraph\\pregel\\main.py:2647\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2645\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2646\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2647\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2648\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2649\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2650\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2651\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2652\u001b[0m ):\n\u001b[0;32m   2653\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2654\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[0;32m   2655\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[0;32m   2656\u001b[0m     )\n\u001b[0;32m   2657\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32mc:\\Users\\Gaurav Pathak\\OneDrive\\Desktop\\Langgraph\\langvenv\\lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\Gaurav Pathak\\OneDrive\\Desktop\\Langgraph\\langvenv\\lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\Gaurav Pathak\\OneDrive\\Desktop\\Langgraph\\langvenv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:659\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m                 \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    658\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 659\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Gaurav Pathak\\OneDrive\\Desktop\\Langgraph\\langvenv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\Gaurav Pathak\\OneDrive\\Desktop\\Langgraph\\langvenv\\lib\\site-packages\\langgraph\\graph\\_branch.py:168\u001b[0m, in \u001b[0;36mBranchSpec._route\u001b[1;34m(self, input, config, reader, writer)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m--> 168\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish(writer, \u001b[38;5;28minput\u001b[39m, result, config)\n",
      "File \u001b[1;32mc:\\Users\\Gaurav Pathak\\OneDrive\\Desktop\\Langgraph\\langvenv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:394\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 394\u001b[0m         ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    396\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "Cell \u001b[1;32mIn[53], line 613\u001b[0m, in \u001b[0;36mroute_choice\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m    610\u001b[0m     state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(HumanMessage(content\u001b[38;5;241m=\u001b[39mlast_user))\n\u001b[0;32m    612\u001b[0m \u001b[38;5;66;03m# For resume, curriculum, debug, news -> do nothing extra\u001b[39;00m\n\u001b[1;32m--> 613\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcurriculum_agent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Network-Agent Orchestration of Your Multi-Agent System (LLM-classified router)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "from typing import List, Dict\n",
    "import re\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# LangChain / LangGraph\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.types import Command\n",
    "\n",
    "# Tools / APIs\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_community.utilities.semanticscholar import SemanticScholarAPIWrapper\n",
    "\n",
    "from youtube_transcript_api import (\n",
    "    YouTubeTranscriptApi,\n",
    "    NoTranscriptFound,\n",
    "    TranscriptsDisabled,\n",
    "    VideoUnavailable,\n",
    ")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Env & Models\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Optional: Groq model (not required by router, but kept as in your code)\n",
    "hf_model = ChatGroq(model=\"deepseek-r1-distill-llama-70b\")\n",
    "\n",
    "# Primary chat model (HF)\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "#     task=\"text-generation\",\n",
    "#     do_sample=False,\n",
    "#     top_p=1.0,\n",
    "#     top_k=0,\n",
    "#     provider=\"auto\",\n",
    "# )\n",
    "# hf_model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# Quick sanity ping (can be commented out)\n",
    "_ = hf_model.invoke([HumanMessage(content=\"Hello World\")])\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Tools\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# @tool\n",
    "# def youtube_search(query: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Search YouTube for videos related to the query and return top 3 video links with titles.\n",
    "#     \"\"\"\n",
    "#     API_KEY = \"AIzaSyBNBTgze_5FR5VHzfZlxc38iLwr7xyYaHE\"  # (kept as given)\n",
    "#     url = \"https://www.googleapis.com/youtube/v3/search\"\n",
    "#     params = {\n",
    "#         \"part\": \"snippet\",\n",
    "#         \"q\": query,\n",
    "#         \"type\": \"video\",\n",
    "#         \"maxResults\": 3,\n",
    "#         \"key\": API_KEY,\n",
    "#     }\n",
    "#     res = requests.get(url, params=params).json()\n",
    "#     items = res.get(\"items\", [])\n",
    "#     videos = [\n",
    "#         f\"{item['snippet']['title']} - https://www.youtube.com/watch?v={item['id']['videoId']}\"\n",
    "#         for item in items\n",
    "#         if item.get(\"id\", {}).get(\"videoId\")\n",
    "#     ]\n",
    "#     if not videos:\n",
    "#         return \"No related videos found.\"\n",
    "#     return \"\\n\".join(videos)\n",
    "# \n",
    "API_KEY = \"AIzaSyBNBTgze_5FR5VHzfZlxc38iLwr7xyYaHE\"\n",
    "\n",
    "def youtube_search_guaranteed(query: str, max_results=3):\n",
    "    # Step 1: search videos\n",
    "    search_url = \"https://www.googleapis.com/youtube/v3/search\"\n",
    "    params = {\n",
    "        \"part\": \"snippet\",\n",
    "        \"q\": query,\n",
    "        \"type\": \"video\",\n",
    "        \"maxResults\": 20,  # search more for filtering\n",
    "        \"key\": API_KEY,\n",
    "    }\n",
    "    search_res = requests.get(search_url, params=params).json()\n",
    "    items = search_res.get(\"items\", [])\n",
    "    video_ids = [item['id']['videoId'] for item in items if item.get('id', {}).get('videoId')]\n",
    "    if not video_ids:\n",
    "        return []\n",
    "\n",
    "    # Step 2: get video details to filter valid ones\n",
    "    details_url = \"https://www.googleapis.com/youtube/v3/videos\"\n",
    "    params = {\n",
    "        \"part\": \"status,snippet\",\n",
    "        \"id\": \",\".join(video_ids),\n",
    "        \"key\": API_KEY,\n",
    "    }\n",
    "    details_res = requests.get(details_url, params=params).json()\n",
    "    valid_videos = []\n",
    "\n",
    "    for video in details_res.get(\"items\", []):\n",
    "        status = video.get(\"status\", {})\n",
    "        if status.get(\"uploadStatus\") != \"processed\":\n",
    "            continue\n",
    "        if status.get(\"privacyStatus\") != \"public\":\n",
    "            continue\n",
    "        snippet = video.get(\"snippet\", {})\n",
    "        title = snippet.get(\"title\")\n",
    "        vid_id = video.get(\"id\")\n",
    "        link = f\"https://www.youtube.com/watch?v={vid_id}\"\n",
    "        valid_videos.append(f\"{title} - {link}\")\n",
    "        if len(valid_videos) >= max_results:\n",
    "            break\n",
    "\n",
    "    return valid_videos\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ LLM-based Topic Extractor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "\n",
    "@tool\n",
    "def youtube_search_agent(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Deterministically extract main keywords and fetch top 3 valid YouTube videos.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    # Step 1: Extract main topic with simple heuristic (first few nouns / keywords)\n",
    "    # For example, remove \"Explain\", \"Give me\", etc.\n",
    "    cleaned_query = re.sub(\n",
    "        r\"\\b(explain|give me|show|video|tutorial|about|for|the|a|an)\\b\", \"\", query, flags=re.I\n",
    "    )\n",
    "    # Keep only the first 5‚Äì7 words\n",
    "    keywords = \" \".join(cleaned_query.split()[:7])\n",
    "\n",
    "    # Step 2: Search YouTube\n",
    "    videos = youtube_search_guaranteed(keywords)\n",
    "    if not videos:\n",
    "        return \"No valid YouTube videos found for this query.\"\n",
    "    return \"\\n\".join(videos)\n",
    "\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Topic Explanation Tool ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "@tool\n",
    "def topic_explanation(query: str) -> str:\n",
    "    \"\"\" Return a concise conceptual explanation of the topic. \"\"\"\n",
    "    prompt = f\"Explain the concept of '{query}' in 3-5 sentences in a clear, beginner-friendly way.\"\n",
    "    return hf_model.invoke([HumanMessage(content=prompt)]).content\n",
    "\n",
    "\n",
    "@tool\n",
    "def generate_resume(job_description: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a structured resume and cover letter based on the job description.\n",
    "    Returns output in clean, formatted HTML for easy display.\n",
    "    \"\"\"\n",
    "    html_template = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; line-height: 1.5; }}\n",
    "            h2 {{ color: #2E86C1; }}\n",
    "            h3 {{ color: #117A65; }}\n",
    "            p {{ margin-bottom: 10px; }}\n",
    "            .section {{ margin-bottom: 20px; }}\n",
    "            .highlight {{ color: #D35400; font-weight: bold; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"section\">\n",
    "            <h2>üìÑ Resume - Tailored for: {job_description}</h2>\n",
    "            <h3>Summary</h3>\n",
    "            <p>Experienced professional with skills and expertise matching <span class=\"highlight\">{job_description}</span>. \n",
    "            Strong problem-solving abilities and a passion for excellence in the relevant field.</p>\n",
    "        </div>\n",
    "        <div class=\"section\">\n",
    "            <h3>Skills</h3>\n",
    "            <p>‚Ä¢ Core skills relevant to {job_description}<br>\n",
    "               ‚Ä¢ Additional complementary skills<br>\n",
    "               ‚Ä¢ Technical & soft skills</p>\n",
    "        </div>\n",
    "        <div class=\"section\">\n",
    "            <h3>Experience</h3>\n",
    "            <p>‚Ä¢ Previous roles and achievements tailored to {job_description}<br>\n",
    "               ‚Ä¢ Demonstrated impact and measurable results</p>\n",
    "        </div>\n",
    "        <div class=\"section\">\n",
    "            <h2>‚úâÔ∏è Cover Letter</h2>\n",
    "            <p>Dear Hiring Manager,</p>\n",
    "            <p>I am excited to apply for the <span class=\"highlight\">{job_description}</span> role. \n",
    "            With my background, skills, and passion for this field, I am confident in delivering impactful results. \n",
    "            I look forward to contributing to your team‚Äôs success.</p>\n",
    "            <p>Best regards,<br>Your Name</p>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return html_template\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(url: str, max_pages: int = 5) -> str:\n",
    "    try:\n",
    "        response = requests.get(url, timeout=15)\n",
    "        if response.status_code != 200:\n",
    "            return \"\"\n",
    "        pdf_file = BytesIO(response.content)\n",
    "        reader = PdfReader(pdf_file)\n",
    "        text = [page.extract_text() or \"\" for page in reader.pages[:max_pages]]\n",
    "        return \"\\n\".join(text)\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting PDF: {e}\"\n",
    "\n",
    "\n",
    "# Semantic Scholar wrapper\n",
    "ss = SemanticScholarAPIWrapper(\n",
    "    top_k_results=5,\n",
    "    load_max_docs=5\n",
    ")\n",
    "\n",
    "@tool\n",
    "def semantic_scholar_research(query: str, summarize: bool = True) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch top research papers from Semantic Scholar for a query.\n",
    "    - Optionally summarize abstracts using LLM.\n",
    "    - Attempt PDF extraction if URL is provided.\n",
    "    \"\"\"\n",
    "    raw_results = ss.run(query)  # returns string with paper info (lib‚Äôs format)\n",
    "    papers = raw_results.split(\"\\n\\n\")\n",
    "    summarized_papers = []\n",
    "\n",
    "    for paper in papers:\n",
    "        summary = \"\"\n",
    "        pdf_summary = \"\"\n",
    "        if summarize and \"abstract:\" in paper.lower():\n",
    "            prompt = f\"Summarize this research abstract in 2-3 sentences:\\n\\n{paper}\"\n",
    "            summary = hf_model.invoke([HumanMessage(content=prompt)]).content\n",
    "\n",
    "        if \"http\" in paper and \".pdf\" in paper.lower():\n",
    "            pdf_url = \"http\" + paper.split(\"http\")[1].split()[0]\n",
    "            pdf_text = extract_text_from_pdf(pdf_url)\n",
    "            if pdf_text and summarize:\n",
    "                pdf_prompt = f\"Summarize this PDF content (first 500 words):\\n\\n{pdf_text[:3000]}\"\n",
    "                pdf_summary = hf_model.invoke([HumanMessage(content=pdf_prompt)]).content\n",
    "\n",
    "        summarized_papers.append(\n",
    "            {\n",
    "                \"raw_info\": paper,\n",
    "                \"summary\": summary,\n",
    "                \"pdf_summary\": pdf_summary,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return summarized_papers\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# YouTube QA Tooling\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "yt_prompt_template = \"\"\"\n",
    "You are a helpful assistant designed to answer questions about a YouTube video based on its transcript.\n",
    "Answer the user's question using ONLY the provided transcript context.\n",
    "If the information is not in the context, explicitly say \"I cannot find information about that in the video transcript.\"\n",
    "\n",
    "Transcript:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "yt_prompt = PromptTemplate(\n",
    "    template=yt_prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "def get_transcript(video_id: str):\n",
    "    \"\"\"Fetch transcript safely for old and new versions of youtube_transcript_api.\"\"\"\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi().fetch(video_id, languages=[\"hi\"])\n",
    "    except NoTranscriptFound:\n",
    "        try:\n",
    "            transcript_list = YouTubeTranscriptApi().fetch(video_id, languages=[\"en\"])\n",
    "        except NoTranscriptFound:\n",
    "            return None, \"No transcript available in Hindi or English.\"\n",
    "    except (TranscriptsDisabled, VideoUnavailable) as e:\n",
    "        return None, str(e)\n",
    "    except Exception as e:\n",
    "        return None, f\"Unexpected error: {str(e)}\"\n",
    "\n",
    "    texts = []\n",
    "    for snippet in transcript_list:\n",
    "        if isinstance(snippet, dict):\n",
    "            texts.append(snippet.get(\"text\", \"\"))\n",
    "        else:\n",
    "            texts.append(getattr(snippet, \"text\", \"\"))\n",
    "    transcript = \" \".join(texts)\n",
    "    return transcript, None\n",
    "\n",
    "\n",
    "@tool\n",
    "def youtube_qa(video_url: str, question: str):\n",
    "    \"\"\"Given a YouTube URL and question, return answer based on transcript.\"\"\"\n",
    "    try:\n",
    "        video_id = video_url.split(\"v=\")[-1].split(\"&\")[0]\n",
    "        transcript, error = get_transcript(video_id)\n",
    "        if error:\n",
    "            return error\n",
    "\n",
    "        rag_runnable = (\n",
    "            {\"context\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
    "            | yt_prompt\n",
    "            | hf_model\n",
    "        )\n",
    "        answer = rag_runnable.invoke({\"context\": transcript, \"question\": question})\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# External Search Tools\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "duck_tool = DuckDuckGoSearchRun()\n",
    "tavily_tool = TavilySearch()\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Agents (unchanged behavior, same prompts & tools)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "unified_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[youtube_qa, semantic_scholar_research],\n",
    "    name=\"unified_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are UNIFIED-AGENT, capable of handling YouTube transcript QA and research paper summarization.\n",
    "- If a valid YouTube link is provided, use youtube_qa to answer or summarize the transcript.\n",
    "- If a research query or PDF link is provided, use semantic_scholar_research to fetch and summarize papers.\n",
    "- Indicate the source clearly (video or research paper).\n",
    "- If info is unavailable, say so explicitly.\n",
    "- Always provide concise, clear, and user-friendly answers.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# @tool\n",
    "# def topic_explanation(query: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Return a concise conceptual explanation of the topic.\n",
    "#     \"\"\"\n",
    "#     prompt = f\"Explain the concept of '{query}' in 3-5 sentences in a clear, beginner-friendly way.\"\n",
    "#     return hf_model.invoke([HumanMessage(content=prompt)]).content\n",
    "\n",
    "# Now the curriculum agent only orchestrates:\n",
    "# curriculum_agent = create_react_agent(\n",
    "#     model=hf_model,\n",
    "#     tools=[duck_tool, youtube_search, topic_explanation],\n",
    "#     name=\"curriculum_agent\",\n",
    "#     prompt=\"\"\"\n",
    "# You are CURRICULUM-GUIDE, a knowledgeable educational expert.\n",
    "\n",
    "# Instructions:\n",
    "# 1. Use the `topic_explanation` tool to generate a clear textual explanation of the user's query.\n",
    "# 2. Use the `youtube_search` tool to fetch **real, top 3 YouTube video links** for the topic.\n",
    "# 3. Provide optional learning steps after explanation and videos.\n",
    "# 4. Format output exactly like this:\n",
    "\n",
    "# Explanation:\n",
    "# [Use topic_explanation output] and if link is not find then not return this type somethng below-' [Exact URL i]'\n",
    "\n",
    "# YouTube Videos:\n",
    "# 1. [Exact title 1] - [Exact URL 1]\n",
    "# 2. [Exact title 2] - [Exact URL 2]\n",
    "# 3. [Exact title 3] - [Exact URL 3]\n",
    "\n",
    "# Learning Steps (optional):\n",
    "# 1. Step one\n",
    "# 2. Step two\n",
    "# 3. Step three\n",
    "\n",
    "# Always:\n",
    "# - Use **actual video links** returned by `youtube_search`, never invented links.\n",
    "# - Keep explanation and steps concise, clear, and informative.\n",
    "# \"\"\"\n",
    "# )\n",
    "curriculum_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[topic_explanation, youtube_search_agent],\n",
    "    name=\"curriculum_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are CURRICULUM-GUIDE, a knowledgeable educational expert.\n",
    "\n",
    "Instructions:\n",
    "1. Use topic_explanation to generate a clear explanation.\n",
    "2. Use youtube_search_agent to fetch **top 3 valid YouTube videos**.\n",
    "3. Provide optional learning steps after explanation.\n",
    "4. Never hallucinate video links. If youtube_search_agent returns empty, skip the YouTube section.\n",
    "\n",
    "Format output like this:\n",
    "\n",
    "Explanation:\n",
    "[Explanation text]\n",
    "\n",
    "YouTube Videos:\n",
    "1. [Video 1 title] - [Video 1 URL]\n",
    "2. [Video 2 title] - [Video 2 URL]\n",
    "3. [Video 3 title] - [Video 3 URL]\n",
    "\n",
    "Learning Steps (optional):\n",
    "1. Step one\n",
    "2. Step two\n",
    "3. Step three\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "debug_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[youtube_search, duck_tool, tavily_tool],\n",
    "    name=\"debug_educational_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are CODE-TUTOR, a friendly and knowledgeable AI teacher and coding mentor. \n",
    "When a student asks a question or submits code, follow these rules:\n",
    "\n",
    "1. **Explain concepts clearly** in an educational and beginner-friendly manner.\n",
    "2. **Debug the code**: identify errors, explain why they occur, and suggest precise fixes.\n",
    "3. **Provide learning resources**: include relevant YouTube links or tutorials . \n",
    "4. **Give examples, exercises, or mini-quizzes** when helpful to reinforce understanding.\n",
    "5. **Motivate the student**: encourage practice, exploration, and curiosity.\n",
    "6. **Step-by-step guidance**: never give one-line answers; always walk the student through solutions.\n",
    "7. **Format output clearly**: use numbered steps, bullet points, or code blocks where applicable.\n",
    "\n",
    "Goal: Deliver comprehensive, interactive, and motivational educational guidance with youtube video.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "resume_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[generate_resume],\n",
    "    name=\"resume_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are RESUME-GUIDE, an expert in generating resumes and cover letters. Your task is to produce\n",
    "a high-quality, professional, structured resume and cover letter for the given job description.\n",
    "\n",
    "Rules:\n",
    "1. Use the provided generate_resume tool for producing HTML output.\n",
    "2. Tailor content dynamically to match the job description.\n",
    "3. Ensure output is balanced: concise yet informative, highlighting key skills, achievements, and fit.\n",
    "4. Internally iterate if needed to refine clarity, professionalism, and formatting.\n",
    "5. Return only the **final polished HTML output** without any internal messages.\n",
    "\n",
    "Sections to include:\n",
    "- Summary\n",
    "- Skills\n",
    "- Experience\n",
    "- Cover Letter\n",
    "\n",
    "Goal: Generate a professional, polished, and ready-to-use resume + cover letter.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "news_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[tavily_tool, duck_tool, youtube_search],\n",
    "    name=\"news_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are TECH-TREND-GUIDE, a proactive and knowledgeable technology analyst. Your task:\n",
    "\n",
    "1. Fetch the latest and trending technology news from multiple sources dynamically.\n",
    "2. Summarize each news point clearly in **point-wise format** for quick reading.\n",
    "3. Highlight **emerging tools, frameworks, and technologies** mentioned or relevant.\n",
    "4. Include **YouTube videos** if they are educational, relevant, and verified. If no video is available, skip gracefully.\n",
    "5. Provide **actionable insights or recommendations** wherever possible.\n",
    "6. Decide intelligently which tool (tavily_tool, duck_tool, or youtube_search) to use for each query.\n",
    "7. Keep the summary **concise, engaging, and readable**; avoid overly long paragraphs.\n",
    "8. Return **only the final summarized news**, do not include internal reasoning or tool calls.\n",
    "\n",
    "Example output format:\n",
    "- News Point 1: [Brief summary]  \n",
    "  Video (if available): [YouTube link]  \n",
    "- News Point 2: [Brief summary]  \n",
    "  Video (if available): [YouTube link]  \n",
    "- Trending Tools/Tech: [List of tools or technologies]  \n",
    "- Recommendation: [Optional actionable insight]\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# LLM-based Intent Classifier for Routing\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "_ALLOWED_INTENTS = [\"curriculum\", \"debug\", \"resume\", \"unified\", \"news\"]\n",
    "\n",
    "_CLASSIFY_SYSTEM = SystemMessage(\n",
    "    content=(\n",
    "        \"You are a router that classifies user messages into one of these intents:\\n\"\n",
    "        f\"{', '.join(_ALLOWED_INTENTS)}.\\n\"\n",
    "        \"Return ONLY the intent name (single lowercase word). No punctuation, no extra text.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "def classify_intent(user_text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Classify user query into one or more agents.\n",
    "    Returns a list of intents for multi-step queries.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a dynamic intent classifier for a multi-agent system.\n",
    "You must determine which agent(s) should handle the user's query.\n",
    "\n",
    "Agents:\n",
    "1. curriculum - learning guides, roadmaps, explanations\n",
    "2. debug - code debugging, errors, analysis\n",
    "3. resume - resumes, cover letters, CVs\n",
    "4. unified - research papers, PDFs, YouTube QA, summarization\n",
    "5. news - tech news, trends, updates\n",
    "\n",
    "Instructions:\n",
    "- Analyze the user's query carefully.\n",
    "- Return a COMMA-SEPARATED list of agent names that should be invoked in order.\n",
    "- Return only valid agent names, lowercase, no punctuation.\n",
    "- Examples:\n",
    "  \"Create a resume and a learning roadmap\" -> \"resume,curriculum\"\n",
    "  \"Summarize a YouTube video on AI\" -> \"unified\"\n",
    "  \"Fix Python code with KeyError\" -> \"debug\"\n",
    "\n",
    "User Query:\n",
    "\\\"\\\"\\\"{user_text}\\\"\\\"\\\"\n",
    "\n",
    "Agent(s):\n",
    "\"\"\"\n",
    "    msg = HumanMessage(content=prompt)\n",
    "    try:\n",
    "        response = hf_model.invoke([_CLASSIFY_SYSTEM, msg]).content.strip().lower()\n",
    "        # Clean and split\n",
    "        intents = [i.strip() for i in response.split(\",\") if i.strip() in _ALLOWED_INTENTS]\n",
    "        return intents if intents else [\"curriculum\"]\n",
    "    except Exception:\n",
    "        return [\"curriculum\"]\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Router Node + Graph (Network Pattern)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# We‚Äôll use MessagesState so messages flow naturally between nodes.\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "def router_node(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"No-op node; conditional edges below decide the next hop.\"\"\"\n",
    "    return state\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_youtube_url(text: str) -> str:\n",
    "    \"\"\"Extract first YouTube URL from the text, or return None.\"\"\"\n",
    "    match = re.search(r\"(https?://www\\.youtube\\.com/watch\\?v=[\\w-]+)\", text)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "\n",
    "def preprocess_message_for_unified(message: str) -> str:\n",
    "    url = extract_youtube_url(message)\n",
    "    if url:\n",
    "        question = message.replace(url, \"\").strip()\n",
    "        # Format as structured call for youtube_qa\n",
    "        return f\"youtube_qa video_url={url} question={question}\"\n",
    "    return message\n",
    "\n",
    "\n",
    "def route_choice(state: MessagesState) -> str:\n",
    "    last_user = \"\"\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if getattr(m, \"type\", None) == \"human\" or getattr(m, \"role\", \"\") == \"user\":\n",
    "            last_user = m.content if hasattr(m, \"content\") else (m.get(\"content\", \"\") if isinstance(m, dict) else \"\")\n",
    "            break\n",
    "\n",
    "    intent = classify_intent(last_user)\n",
    "    mapping = {\n",
    "        \"curriculum\": \"curriculum_agent\",\n",
    "        \"debug\": \"debug_agent\",\n",
    "        \"resume\": \"resume_agent\",\n",
    "        \"unified\": \"unified_agent\",\n",
    "        \"news\": \"news_agent\",\n",
    "    }\n",
    "\n",
    "    if intent == \"unified\":\n",
    "        # Preprocess only for unified\n",
    "        last_user = preprocess_message_for_unified(last_user)\n",
    "        state[\"messages\"].append(HumanMessage(content=last_user))\n",
    "\n",
    "    # For resume, curriculum, debug, news -> do nothing extra\n",
    "    return mapping.get(intent, \"curriculum_agent\")\n",
    "\n",
    "\n",
    "# Nodes\n",
    "builder.add_node(\"router\", router_node)\n",
    "\n",
    "# Agent nodes (callables from create_react_agent)\n",
    "builder.add_node(\"curriculum_agent\", curriculum_agent)\n",
    "builder.add_node(\"debug_agent\", debug_agent)\n",
    "builder.add_node(\"resume_agent\", resume_agent)\n",
    "builder.add_node(\"unified_agent\", unified_agent)\n",
    "builder.add_node(\"news_agent\", news_agent)\n",
    "\n",
    "# Flow\n",
    "builder.add_edge(START, \"router\")\n",
    "builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    route_choice,\n",
    "    {\n",
    "        \"curriculum_agent\": \"curriculum_agent\",\n",
    "        \"debug_agent\": \"debug_agent\",\n",
    "        \"resume_agent\": \"resume_agent\",\n",
    "        \"unified_agent\": \"unified_agent\",\n",
    "        \"news_agent\": \"news_agent\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# End after each agent completes\n",
    "builder.add_edge(\"curriculum_agent\", END)\n",
    "builder.add_edge(\"debug_agent\", END)\n",
    "builder.add_edge(\"resume_agent\", END)\n",
    "builder.add_edge(\"unified_agent\", END)\n",
    "builder.add_edge(\"news_agent\", END)\n",
    "\n",
    "# Compile app\n",
    "network_app = builder.compile()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Example: invoke\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: curriculum-style query\n",
    "    q1 = \"Create a resume and cover letter for a Software Engineer internship\"\n",
    "    result1 = network_app.invoke({\"messages\": [{\"role\": \"user\", \"content\": q1}]})\n",
    "    for m in result1[\"messages\"]:\n",
    "        if hasattr(m, \"content\"):\n",
    "            print(m.content)\n",
    "            print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab0d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b85f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Function must have a docstring if description not provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 69\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m valid_videos\n\u001b[0;32m     68\u001b[0m \u001b[38;5;129;43m@tool\u001b[39;49m\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43myoutube_search_agent\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcleaned_query\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mb(explain|give me|show|video|tutorial|about|for|the|a|an)\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_query\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gaurav Pathak\\OneDrive\\Desktop\\Langgraph\\langvenv\\lib\\site-packages\\langchain_core\\tools\\convert.py:321\u001b[0m, in \u001b[0;36mtool\u001b[1;34m(name_or_callable, runnable, description, return_direct, args_schema, infer_schema, response_format, parse_docstring, error_on_invalid_docstring, *args)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name_or_callable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(name_or_callable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(name_or_callable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    317\u001b[0m         \u001b[38;5;66;03m# Used as a decorator without parameters\u001b[39;00m\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# @tool\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;66;03m# def my_tool():\u001b[39;00m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;66;03m#    pass\u001b[39;00m\n\u001b[1;32m--> 321\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_tool_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_callable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_callable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name_or_callable, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;66;03m# Used with a new name for the tool\u001b[39;00m\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;66;03m# @tool(\"search\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;66;03m# def my_tool():\u001b[39;00m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;66;03m#    pass\u001b[39;00m\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _create_tool_factory(name_or_callable)\n",
      "File \u001b[1;32mc:\\Users\\Gaurav Pathak\\OneDrive\\Desktop\\Langgraph\\langvenv\\lib\\site-packages\\langchain_core\\tools\\convert.py:266\u001b[0m, in \u001b[0;36mtool.<locals>._create_tool_factory.<locals>._tool_factory\u001b[1;34m(dec_func)\u001b[0m\n\u001b[0;32m    263\u001b[0m     schema \u001b[38;5;241m=\u001b[39m args_schema\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m infer_schema \u001b[38;5;129;01mor\u001b[39;00m args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStructuredTool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoroutine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_direct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_direct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_docstring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_docstring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_on_invalid_docstring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_invalid_docstring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# If someone doesn't want a schema applied, we must treat it as\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# a simple string->string function\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dec_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Gaurav Pathak\\OneDrive\\Desktop\\Langgraph\\langvenv\\lib\\site-packages\\langchain_core\\tools\\structured.py:219\u001b[0m, in \u001b[0;36mStructuredTool.from_function\u001b[1;34m(cls, func, coroutine, name, description, return_direct, args_schema, infer_schema, response_format, parse_docstring, error_on_invalid_docstring, **kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m description_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction must have a docstring if description not provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m description \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# Only apply if using the function's docstring\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     description_ \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mdedent(description_)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mValueError\u001b[0m: Function must have a docstring if description not provided."
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Dynamic Multi-Agent Network (Context-Aware Router)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "from typing import List\n",
    "import re\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_huggingface import ChatHuggingFace\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_community.utilities.semanticscholar import SemanticScholarAPIWrapper\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled, VideoUnavailable\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Env & Models\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "load_dotenv()\n",
    "# hf_model = ChatGroq(model=\"deepseek-r1-distill-llama-70b\")\n",
    "# _ = hf_model.invoke([HumanMessage(content=\"Hello World\")])\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Tools\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "API_KEY = \"AIzaSyBNBTgze_5FR5VHzfZlxc38iLwr7xyYaHE\"\n",
    "\n",
    "def youtube_search_guaranteed(query: str, max_results=3):\n",
    "    search_url = \"https://www.googleapis.com/youtube/v3/search\"\n",
    "    params = {\"part\": \"snippet\", \"q\": query, \"type\": \"video\", \"maxResults\": 20, \"key\": API_KEY}\n",
    "    search_res = requests.get(search_url, params=params).json()\n",
    "    items = search_res.get(\"items\", [])\n",
    "    video_ids = [item['id']['videoId'] for item in items if item.get('id', {}).get('videoId')]\n",
    "    if not video_ids:\n",
    "        return []\n",
    "\n",
    "    details_url = \"https://www.googleapis.com/youtube/v3/videos\"\n",
    "    params = {\"part\": \"status,snippet\", \"id\": \",\".join(video_ids), \"key\": API_KEY}\n",
    "    details_res = requests.get(details_url, params=params).json()\n",
    "    valid_videos = []\n",
    "\n",
    "    for video in details_res.get(\"items\", []):\n",
    "        status = video.get(\"status\", {})\n",
    "        if status.get(\"uploadStatus\") != \"processed\" or status.get(\"privacyStatus\") != \"public\":\n",
    "            continue\n",
    "        snippet = video.get(\"snippet\", {})\n",
    "        title = snippet.get(\"title\")\n",
    "        vid_id = video.get(\"id\")\n",
    "        valid_videos.append(f\"{title} - https://www.youtube.com/watch?v={vid_id}\")\n",
    "        if len(valid_videos) >= max_results:\n",
    "            break\n",
    "    return valid_videos\n",
    "\n",
    "@tool\n",
    "def youtube_search_agent(query: str) -> str:\n",
    "    cleaned_query = re.sub(r\"\\b(explain|give me|show|video|tutorial|about|for|the|a|an)\\b\", \"\", query, flags=re.I)\n",
    "    keywords = \" \".join(cleaned_query.split()[:7])\n",
    "    videos = youtube_search_guaranteed(keywords)\n",
    "    if not videos:\n",
    "        return \"No valid YouTube videos found.\"\n",
    "    return \"\\n\".join(videos)\n",
    "\n",
    "@tool\n",
    "def topic_explanation(query: str) -> str:\n",
    "    prompt = f\"Explain the concept of '{query}' in 3-5 sentences, clearly and beginner-friendly.\"\n",
    "    return hf_model.invoke([HumanMessage(content=prompt)]).content\n",
    "\n",
    "@tool\n",
    "def resume_tool(user_query: str, existing_resume: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Dynamically decide whether to:\n",
    "    1. Generate a new resume + cover letter (if no existing_resume provided)\n",
    "    2. Review and provide feedback on an existing resume (if existing_resume provided)\n",
    "    \"\"\"\n",
    "    if existing_resume:\n",
    "        mode = \"review\"\n",
    "    else:\n",
    "        mode = \"create\"\n",
    "\n",
    "    if mode == \"create\":\n",
    "        html_template = f\"\"\"\n",
    "        <html><body>\n",
    "        <h2>Resume - Tailored for: {user_query}</h2>\n",
    "        <h3>Summary</h3><p>Experienced professional with skills matching {user_query}.</p>\n",
    "        <h3>Skills</h3><p>‚Ä¢ Core skills relevant to {user_query}</p>\n",
    "        <h3>Experience</h3><p>‚Ä¢ Tailored achievements and impact.</p>\n",
    "        <h3>Cover Letter</h3><p>Dear Hiring Manager, I am excited to apply for {user_query}...</p>\n",
    "        </body></html>\n",
    "        \"\"\"\n",
    "        return html_template\n",
    "    else:\n",
    "        prompt = f\"\"\"\n",
    "You are a professional resume reviewer. Analyze the following resume and provide:\n",
    "1. Key improvements needed\n",
    "2. Formatting & clarity feedback\n",
    "3. Skills & experience suggestions\n",
    "\n",
    "Resume Content:\n",
    "{existing_resume}\n",
    "\n",
    "Return a structured, concise, and constructive feedback.\n",
    "\"\"\"\n",
    "        feedback = hf_model.invoke([HumanMessage(content=prompt)]).content\n",
    "        return feedback\n",
    "\n",
    "def extract_text_from_pdf(url: str, max_pages: int = 5) -> str:\n",
    "    try:\n",
    "        response = requests.get(url, timeout=15)\n",
    "        if response.status_code != 200: return \"\"\n",
    "        reader = PdfReader(BytesIO(response.content))\n",
    "        text = [page.extract_text() or \"\" for page in reader.pages[:max_pages]]\n",
    "        return \"\\n\".join(text)\n",
    "    except Exception: return \"\"\n",
    "\n",
    "ss = SemanticScholarAPIWrapper(top_k_results=5, load_max_docs=5)\n",
    "\n",
    "@tool\n",
    "def semantic_scholar_research(query: str, summarize: bool = True) -> list:\n",
    "    \n",
    "    raw_results = ss.run(query)\n",
    "    papers = raw_results.split(\"\\n\\n\")\n",
    "    summarized = []\n",
    "    for paper in papers:\n",
    "        summary, pdf_summary = \"\", \"\"\n",
    "        if summarize and \"abstract:\" in paper.lower():\n",
    "            summary = hf_model.invoke([HumanMessage(content=f\"Summarize this abstract in 2-3 sentences:\\n\\n{paper}\")]).content\n",
    "        if \"http\" in paper and \".pdf\" in paper.lower():\n",
    "            pdf_url = \"http\" + paper.split(\"http\")[1].split()[0]\n",
    "            pdf_text = extract_text_from_pdf(pdf_url)\n",
    "            if pdf_text and summarize:\n",
    "                pdf_summary = hf_model.invoke([HumanMessage(content=f\"Summarize PDF first 500 words:\\n\\n{pdf_text[:3000]}\")]).content\n",
    "        summarized.append({\"raw_info\": paper, \"summary\": summary, \"pdf_summary\": pdf_summary})\n",
    "    return summarized\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Agents\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "duck_tool = DuckDuckGoSearchRun()\n",
    "tavily_tool = TavilySearch()\n",
    "\n",
    "curriculum_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[topic_explanation, youtube_search_agent],\n",
    "    name=\"curriculum_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are CURRICULUM-GUIDE, an expert in learning and concept explanations.\n",
    "\n",
    "Rules:\n",
    "1. Use topic_explanation to provide clear step-by-step conceptual explanations.\n",
    "2. Use youtube_search_agent to fetch **top 3 valid YouTube videos**.\n",
    "3. Include optional learning steps if helpful.\n",
    "4. Dynamically handle queries: if the user asks for tutorials, learning paths, or conceptual understanding, provide a concise, structured response.\n",
    "5. Never hallucinate video links. Skip YouTube section if none found.\n",
    "6. Return only the **final output**, well-formatted and readable.\n",
    "\"\"\"\n",
    ")\n",
    "debug_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[youtube_search_agent, duck_tool, tavily_tool],\n",
    "    name=\"debug_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are CODE-TUTOR, a friendly AI coding mentor.\n",
    "\n",
    "Rules:\n",
    "1. Dynamically detect whether the query is:\n",
    "   - Code debugging\n",
    "   - Explaining a programming concept\n",
    "   - Providing exercises/examples\n",
    "2. Explain concepts step-by-step, clearly and beginner-friendly.\n",
    "3. Suggest precise fixes if code errors exist.\n",
    "4. Attach relevant YouTube tutorials or resources dynamically.\n",
    "5. Include mini-exercises or examples if relevant.\n",
    "6. Always return **final output**, structured, and concise.\n",
    "\"\"\"\n",
    ")\n",
    "resume_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[resume_tool],\n",
    "    name=\"resume_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are RESUME-GUIDE. Your task is to dynamically decide if the user wants to:\n",
    "1. Create a resume + cover letter\n",
    "2. Review an existing resume for improvements\n",
    "\n",
    "Rules:\n",
    "- If the user provides an existing resume, call resume_tool in 'review' mode.\n",
    "- Otherwise, call resume_tool in 'create' mode using job description in the query.\n",
    "- Output should be polished, structured, and user-friendly.\n",
    "- Always return only the final output (HTML or text feedback).\n",
    "\"\"\"\n",
    ")\n",
    "unified_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[youtube_search_agent, semantic_scholar_research],\n",
    "    name=\"unified_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are UNIFIED-AGENT, capable of handling:\n",
    "- Research papers\n",
    "- Academic queries\n",
    "- YouTube transcript QA\n",
    "- Content summarization\n",
    "\n",
    "Rules:\n",
    "1. Detect if a query contains a YouTube link ‚Üí call youtube_qa.\n",
    "2. Detect if a query is research-focused ‚Üí call semantic_scholar_research.\n",
    "3. Summarize clearly, citing sources explicitly.\n",
    "4. If no info is available, respond clearly.\n",
    "5. Always return **concise, user-friendly output**.\n",
    "\"\"\"\n",
    ")\n",
    "news_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[tavily_tool, duck_tool, youtube_search_agent],\n",
    "    name=\"news_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are TECH-TREND-GUIDE, an expert in technology news and trends.\n",
    "\n",
    "Rules:\n",
    "1. Dynamically detect tech news or trend queries.\n",
    "2. Fetch latest updates via tavily_tool or duck_tool.\n",
    "3. Include relevant YouTube videos if educational.\n",
    "4. Summarize in **point-wise format**, highlighting tools, frameworks, and recommendations.\n",
    "5. Keep it concise, actionable, and readable.\n",
    "6. Return only **final output**, no internal reasoning.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Dynamic Router Node\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def dynamic_router_node(state: MessagesState) -> MessagesState:\n",
    "    last_user = \"\"\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if getattr(m, \"role\", \"\") == \"user\":\n",
    "            last_user = m.content\n",
    "            break\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an intelligent router for a multi-agent system.\n",
    "Analyze the user's query and determine which agents to invoke.\n",
    "Return **JSON array of agent names** in order (any of: curriculum_agent, debug_agent, resume_agent, unified_agent, news_agent).\n",
    "\n",
    "Example:\n",
    "- 'Create resume' -> [\"resume_agent\"]\n",
    "- 'Review my resume' -> [\"debug_agent\"]\n",
    "- 'Explain OOP and give roadmap' -> [\"curriculum_agent\"]\n",
    "\n",
    "User Query:\n",
    "\\\"\\\"\\\"{last_user}\\\"\\\"\\\"\n",
    "\n",
    "Agents JSON:\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = hf_model.invoke([HumanMessage(content=prompt)]).content.strip()\n",
    "        agents_to_call = json.loads(response)\n",
    "        if not isinstance(agents_to_call, list) or not agents_to_call:\n",
    "            agents_to_call = [\"curriculum_agent\"]\n",
    "    except Exception:\n",
    "        agents_to_call = [\"curriculum_agent\"]\n",
    "\n",
    "    # Add a human message marker for each agent\n",
    "    for agent_name in agents_to_call:\n",
    "        state[\"messages\"].append(HumanMessage(content=f\"[CALL_AGENT]{agent_name}\"))\n",
    "\n",
    "    return state\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Graph Network\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"router\", dynamic_router_node)\n",
    "builder.add_node(\"curriculum_agent\", curriculum_agent)\n",
    "builder.add_node(\"debug_agent\", debug_agent)\n",
    "builder.add_node(\"resume_agent\", resume_agent)\n",
    "builder.add_node(\"unified_agent\", unified_agent)\n",
    "builder.add_node(\"news_agent\", news_agent)\n",
    "\n",
    "builder.add_edge(START, \"router\")\n",
    "\n",
    "# Conditional edges: router ‚Üí agents based on HF decision\n",
    "builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    lambda state: [msg.content.replace(\"[CALL_AGENT]\", \"\") for msg in state[\"messages\"] if \"[CALL_AGENT]\" in msg.content],\n",
    "    {\n",
    "        \"curriculum_agent\": \"curriculum_agent\",\n",
    "        \"debug_agent\": \"debug_agent\",\n",
    "        \"resume_agent\": \"resume_agent\",\n",
    "        \"unified_agent\": \"unified_agent\",\n",
    "        \"news_agent\": \"news_agent\",\n",
    "    },\n",
    ")\n",
    "\n",
    "for agent in [\"curriculum_agent\", \"debug_agent\", \"resume_agent\", \"unified_agent\", \"news_agent\"]:\n",
    "    builder.add_edge(agent, END)\n",
    "\n",
    "network_app = builder.compile()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Example usage\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    queries = [\n",
    "        \"Create a resume and cover letter for Software Engineer\",\n",
    "        \"Review my resume for improvements\",\n",
    "        \"Explain Object-Oriented Programming and provide learning roadmap\",\n",
    "        \"Latest trends in AI technologies\"\n",
    "    ]\n",
    "    for q in queries:\n",
    "        result = network_app.invoke({\"messages\": [{\"role\": \"user\", \"content\": q}]})\n",
    "        for m in result[\"messages\"]:\n",
    "            if hasattr(m, \"content\"):\n",
    "                print(m.content)\n",
    "                print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c2a2a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[youtube_qa, semantic_scholar_research],\n",
    "    name=\"unified_agent\",  # <-- rename from \"knowledge_agent\"\n",
    "    prompt=\"\"\"\n",
    "You are UNIFIED-AGENT, capable of handling YouTube transcript QA and research paper summarization.\n",
    "- If a valid YouTube link is provided, use youtube_qa to answer or summarize the transcript.\n",
    "- If a research query or PDF link is provided, use semantic_scholar_research to fetch and summarize papers.\n",
    "- Indicate the source clearly (video or research paper).\n",
    "- If info is unavailable, say so explicitly.\n",
    "- Always provide concise, clear, and user-friendly answers.\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "58087bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curriculum_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[duck_tool, youtube_search],\n",
    "    name=\"curriculum_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are CURRICULUM-GUIDE, a knowledgeable educational expert.\n",
    "\n",
    "Rules:\n",
    "\n",
    "1. Generate a **personalized learning roadmap** based on the user's query.\n",
    "2. Always fetch **top 3 YouTube videos** for the topic using the `youtube_search` tool.\n",
    "   - Include **full video title and URL**.\n",
    "   - Do not truncate, summarize, or remove links.\n",
    "3. If no official video is found, output: \"No related videos found.\"\n",
    "4. Include step-by-step guidance in the roadmap.\n",
    "5. Return only the **final clean output**, do not include internal agent thoughts, actions, or debug messages.\n",
    "6. Format the response like this:\n",
    "\n",
    "- **Course/Topic Name:** [Name]\n",
    "- **Description:** [Brief summary]\n",
    "- **YouTube Videos:** \n",
    "    [Title 1] - [URL 1]\n",
    "    [Title 2] - [URL 2]\n",
    "    [Title 3] - [URL 3]\n",
    "- **Learning Steps:** \n",
    "    1. Step one\n",
    "    2. Step two\n",
    "    3. Step three\n",
    "\n",
    "Always use the **exact output from the youtube_search tool** under \"YouTube Videos\".\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "16e59ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[youtube_search, duck_tool, tavile_tool],\n",
    "    name=\"debug_educational_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are CODE-TUTOR, a friendly and knowledgeable AI teacher and coding mentor. \n",
    "When a student asks a question or submits code, follow these rules:\n",
    "\n",
    "1. **Explain concepts clearly** in an educational and beginner-friendly manner.\n",
    "2. **Debug the code**: identify errors, explain why they occur, and suggest precise fixes.\n",
    "3. **Provide learning resources**: include relevant YouTube links or tutorials . \n",
    "4. **Give examples, exercises, or mini-quizzes** when helpful to reinforce understanding.\n",
    "5. **Motivate the student**: encourage practice, exploration, and curiosity.\n",
    "6. **Step-by-step guidance**: never give one-line answers; always walk the student through solutions.\n",
    "7. **Format output clearly**: use numbered steps, bullet points, or code blocks where applicable.\n",
    "\n",
    "Goal: Deliver comprehensive, interactive, and motivational educational guidance with youtube video.\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c1db9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[generate_resume],\n",
    "    name=\"resume_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are RESUME-GUIDE, an expert in generating resumes and cover letters. Your task is to produce\n",
    "a high-quality, professional, structured resume and cover letter for the given job description.\n",
    "\n",
    "Rules:\n",
    "1. Use the provided generate_resume tool for producing HTML output.\n",
    "2. Tailor content dynamically to match the job description.\n",
    "3. Ensure output is balanced: concise yet informative, highlighting key skills, achievements, and fit.\n",
    "4. Internally iterate if needed to refine clarity, professionalism, and formatting.\n",
    "5. Return only the **final polished HTML output** without any internal messages.\n",
    "\n",
    "Sections to include:\n",
    "- Summary\n",
    "- Skills\n",
    "- Experience\n",
    "- Cover Letter\n",
    "\n",
    "Goal: Generate a professional, polished, and ready-to-use resume + cover letter.\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2ab95158",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_agent = create_react_agent(\n",
    "    model=hf_model,\n",
    "    tools=[tavile_tool, duck_tool, youtube_search],\n",
    "    name=\"news_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are TECH-TREND-GUIDE, a proactive and knowledgeable technology analyst. Your task:\n",
    "\n",
    "1. Fetch the latest and trending technology news from multiple sources dynamically.\n",
    "2. Summarize each news point clearly in **point-wise format** for quick reading.\n",
    "3. Highlight **emerging tools, frameworks, and technologies** mentioned or relevant.\n",
    "4. Include **YouTube videos** if they are educational, relevant, and verified. If no video is available, skip gracefully.\n",
    "5. Provide **actionable insights or recommendations** wherever possible.\n",
    "6. Decide intelligently which tool (tavile_tool, duck_tool, or youtube_search) to use for each query.\n",
    "7. Keep the summary **concise, engaging, and readable**; avoid overly long paragraphs.\n",
    "8. Return **only the final summarized news**, do not include internal reasoning or tool calls.\n",
    "\n",
    "Example output format:\n",
    "- News Point 1: [Brief summary]  \n",
    "  Video (if available): [YouTube link]  \n",
    "- News Point 2: [Brief summary]  \n",
    "  Video (if available): [YouTube link]  \n",
    "- Trending Tools/Tech: [List of tools or technologies]  \n",
    "- Recommendation: [Optional actionable insight]\n",
    "\n",
    "Focus on delivering a **dynamic, insightful, and agentic summary of tech trends**, with links only when they add real value.\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e707b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = create_supervisor(\n",
    "    [\n",
    "        curriculum_agent,\n",
    "        debug_agent,\n",
    "        resume_agent,\n",
    "        unified_agent,  # Handles YouTube QA & research papers\n",
    "        news_agent\n",
    "    ],\n",
    "    model=hf_model,\n",
    "    prompt=\"\"\"\n",
    "You are SUPERVISOR-GUIDE. Route user queries to the correct agent and return a concise, clear, final response.\n",
    "Always provide structured, user-friendly output with valid links where applicable.\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4d9e9389",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ef224554",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_query = (\n",
    "        \"\"\"Now based on this job description create a resume ,description=[About the Internship\n",
    "\n",
    "Are you fascinated by data, machine learning, and AI-driven solutions? Do you want to gain hands-on experience in solving real-world business challenges using cutting-edge technology? As a Data Science Intern, you‚Äôll work on projects that directly impact business decisions in the AdTech ecosystem, customer analytics, and generative AI applications.\n",
    "\n",
    "\n",
    "This internship is designed for freshers who are eager to apply their academic knowledge to industry problems. You‚Äôll collaborate with data scientists, engineers, and product managers to design models, analyze data, and deliver insights that power smarter strategies and solutions for clients.\n",
    "\n",
    "\n",
    "Key Responsibilities\n",
    "\n",
    "As part of the team, you‚Äôll contribute to both research and development tasks, ensuring real business impact:\n",
    "\n",
    "Business Translation: Work closely with stakeholders to translate business requirements into solvable data science problems.\n",
    "Algorithm Development: Design and implement algorithms for multi-channel budget and bid optimization, particularly within the Walled Garden AdTech ecosystem.\n",
    "Customer Analytics: Develop solutions for customer segmentation, churn prediction, and other predictive models using large-scale datasets.\n",
    "Machine Learning: Build and train ML models using Python (Pandas, NumPy, Scikit-learn), focusing on real-world applications like ensemble methods, time series modeling, and boosting techniques.\n",
    "Generative AI: Explore and implement solutions with Large Language Models (LLMs) and Generative AI tailored to client needs.\n",
    "Continuous Improvement: Document, evaluate, and enhance algorithms and models for better performance and scalability.\n",
    "Metrics & Outcomes: Define and track key performance indicators (KPIs) to measure the success of proposed solutions.\n",
    "Collaboration: Partner with a cross-functional team of data scientists, engineers, and product managers throughout the product lifecycle.\n",
    "\n",
    "\n",
    "Skills and Qualifications\n",
    "\n",
    "We‚Äôre looking for motivated learners with a solid foundation in data science concepts:\n",
    "\n",
    "Education: Bachelor‚Äôs degree in Computer Science, Statistics, Mathematics, or related field.\n",
    "Programming: Proficiency in Python and experience with libraries such as Pandas, NumPy, and Scikit-learn.\n",
    "SQL: Intermediate-level skills to query, manage, and analyze large datasets.\n",
    "Machine Learning Knowledge: Familiarity with techniques such as regularization, boosting, random forests, ensemble methods, and time series modeling.\n",
    "AI/ML Exposure: Prior experience or academic projects with LLMs and Generative AI.\n",
    "Additional Plus: Knowledge of REST APIs, web services, and production-grade model deployment.\n",
    "Soft Skills: Strong problem-solving mindset, excellent written and verbal communication, and the ability to work effectively in a team.\n",
    "]\"\"\"\n",
    "    )\n",
    "    \n",
    "result = app.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": student_query}]\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "88432ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Now based on this job description create a resume ,description=[About the Internship\n",
      "\n",
      "Are you fascinated by data, machine learning, and AI-driven solutions? Do you want to gain hands-on experience in solving real-world business challenges using cutting-edge technology? As a Data Science Intern, you‚Äôll work on projects that directly impact business decisions in the AdTech ecosystem, customer analytics, and generative AI applications.\n",
      "\n",
      "\n",
      "This internship is designed for freshers who are eager to apply their academic knowledge to industry problems. You‚Äôll collaborate with data scientists, engineers, and product managers to design models, analyze data, and deliver insights that power smarter strategies and solutions for clients.\n",
      "\n",
      "\n",
      "Key Responsibilities\n",
      "\n",
      "As part of the team, you‚Äôll contribute to both research and development tasks, ensuring real business impact:\n",
      "\n",
      "Business Translation: Work closely with stakeholders to translate business requirements into solvable data science problems.\n",
      "Algorithm Development: Design and implement algorithms for multi-channel budget and bid optimization, particularly within the Walled Garden AdTech ecosystem.\n",
      "Customer Analytics: Develop solutions for customer segmentation, churn prediction, and other predictive models using large-scale datasets.\n",
      "Machine Learning: Build and train ML models using Python (Pandas, NumPy, Scikit-learn), focusing on real-world applications like ensemble methods, time series modeling, and boosting techniques.\n",
      "Generative AI: Explore and implement solutions with Large Language Models (LLMs) and Generative AI tailored to client needs.\n",
      "Continuous Improvement: Document, evaluate, and enhance algorithms and models for better performance and scalability.\n",
      "Metrics & Outcomes: Define and track key performance indicators (KPIs) to measure the success of proposed solutions.\n",
      "Collaboration: Partner with a cross-functional team of data scientists, engineers, and product managers throughout the product lifecycle.\n",
      "\n",
      "\n",
      "Skills and Qualifications\n",
      "\n",
      "We‚Äôre looking for motivated learners with a solid foundation in data science concepts:\n",
      "\n",
      "Education: Bachelor‚Äôs degree in Computer Science, Statistics, Mathematics, or related field.\n",
      "Programming: Proficiency in Python and experience with libraries such as Pandas, NumPy, and Scikit-learn.\n",
      "SQL: Intermediate-level skills to query, manage, and analyze large datasets.\n",
      "Machine Learning Knowledge: Familiarity with techniques such as regularization, boosting, random forests, ensemble methods, and time series modeling.\n",
      "AI/ML Exposure: Prior experience or academic projects with LLMs and Generative AI.\n",
      "Additional Plus: Knowledge of REST APIs, web services, and production-grade model deployment.\n",
      "Soft Skills: Strong problem-solving mindset, excellent written and verbal communication, and the ability to work effectively in a team.\n",
      "]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: supervisor\n",
      "Tool Calls:\n",
      "  transfer_to_resume_agent (call_zbl5tp2scssqhhp05lz3d240)\n",
      " Call ID: call_zbl5tp2scssqhhp05lz3d240\n",
      "  Args:\n",
      "    description: Are you fascinated by data, machine learning, and AI-driven solutions? Do you want to gain hands-on experience in solving real-world business challenges using cutting-edge technology? As a Data Science Intern, you‚Äôll work on projects that directly impact business decisions in the AdTech ecosystem, customer analytics, and generative AI applications.\n",
      "\n",
      "This internship is designed for freshers who are eager to apply their academic knowledge to industry problems. You\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: transfer_to_resume_agent\n",
      "\n",
      "Successfully transferred to resume_agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: resume_agent\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>Data Science Intern Resume</title>\n",
      "    <style>\n",
      "        body {\n",
      "            font-family: Arial, sans-serif;\n",
      "            margin: 0;\n",
      "            padding: 0;\n",
      "        }\n",
      "        .section {\n",
      "            margin-bottom: 20px;\n",
      "        }\n",
      "        .section h2 {\n",
      "            margin-top: 0;\n",
      "        }\n",
      "        .section ul {\n",
      "            list-style: none;\n",
      "            padding: 0;\n",
      "            margin: 0;\n",
      "        }\n",
      "        .section li {\n",
      "            margin-bottom: 10px;\n",
      "        }\n",
      "        .section ul li {\n",
      "            margin-bottom: 10px;\n",
      "        }\n",
      "        .section p {\n",
      "            margin-bottom: 20px;\n",
      "        }\n",
      "    </style>\n",
      "</head>\n",
      "<body>\n",
      "    <header>\n",
      "        <h1>Data Science Intern</h1>\n",
      "    </header>\n",
      "    <section class=\"summary\">\n",
      "        <h2>Summary</h2>\n",
      "        <p>Fresh graduate with a strong foundation in data science concepts, seeking a Data Science Internship to apply academic knowledge to industry problems and gain hands-on experience in solving real-world business challenges using cutting-edge technology.</p>\n",
      "    </section>\n",
      "    <section class=\"skills\">\n",
      "        <h2>Skills</h2>\n",
      "        <ul>\n",
      "            <li>Programming: Proficient in Python and experience with libraries such as Pandas, NumPy, and Scikit-learn.</li>\n",
      "            <li>SQL: Intermediate-level skills to query, manage, and analyze large datasets.</li>\n",
      "            <li>Machine Learning Knowledge: Familiarity with techniques such as regularization, boosting, random forests, ensemble methods, and time series modeling.</li>\n",
      "            <li>AI/ML Exposure: Prior experience or academic projects with LLMs and Generative AI.</li>\n",
      "            <li>Additional Plus: Knowledge of REST APIs, web services, and production-grade model deployment.</li>\n",
      "        </ul>\n",
      "    </section>\n",
      "    <section class=\"experience\">\n",
      "        <h2>Experience</h2>\n",
      "        <ul>\n",
      "            <li>\n",
      "                <h3>Academic Projects</h3>\n",
      "                <p>Designed and implemented algorithms for multi-channel budget and bid optimization, customer segmentation, churn prediction, and other predictive models using large-scale datasets.</p>\n",
      "            </li>\n",
      "            <li>\n",
      "                <h3>Personal Projects</h3>\n",
      "                <p>Developed solutions for customer analytics, generative AI, and machine learning using Python and libraries such as Pandas, NumPy, and Scikit-learn.</p>\n",
      "            </li>\n",
      "        </ul>\n",
      "    </section>\n",
      "    <section class=\"cover-letter\">\n",
      "        <h2>Cover Letter</h2>\n",
      "        <p>\n",
      "            Dear Hiring Manager,\n",
      "            I am excited to apply for the Data Science Intern position at [Company Name]. As a fresh graduate with a strong foundation in data science concepts, I am eager to apply my academic knowledge to industry problems and gain hands-on experience in solving real-world business challenges using cutting-edge technology.\n",
      "            I am confident that my skills and experience make me an ideal candidate for this position. I am proficient in Python and have experience with libraries such as Pandas, NumPy, and Scikit-learn. I also have intermediate-level skills in SQL and familiarity with machine learning techniques such as regularization, boosting, random forests, ensemble methods, and time series modeling.\n",
      "            I am particularly drawn to this internship because of the opportunity to work on projects that directly impact business decisions in the AdTech ecosystem, customer analytics, and generative AI applications. I am excited about the prospect of collaborating with a cross-functional team of data scientists, engineers, and product managers to design models, analyze data, and deliver insights that power smarter strategies and solutions for clients.\n",
      "            Thank you for considering my application. I look forward to the opportunity to discuss my qualifications further.\n",
      "            Sincerely,\n",
      "            [Your Name]\n",
      "        </p>\n",
      "    </section>\n",
      "</body>\n",
      "</html>\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: resume_agent\n",
      "\n",
      "Transferring back to supervisor\n",
      "Tool Calls:\n",
      "  transfer_back_to_supervisor (444cd5f7-8571-4c9d-b3d8-91acc4ef0ca7)\n",
      " Call ID: 444cd5f7-8571-4c9d-b3d8-91acc4ef0ca7\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: transfer_back_to_supervisor\n",
      "\n",
      "Successfully transferred back to supervisor\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: supervisor\n",
      "\n",
      "No transcript available; refer to video description or other sources.\n"
     ]
    }
   ],
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d8aa7bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    student_query = (\n",
    "        \"\"\"Explain the difference between supervised and unsupervised machine learning with yutube video\"\"\"\n",
    "    )\n",
    "    \n",
    "    result = app.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": student_query}]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5ccc6cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None:\n",
      "Explain the difference between supervised and unsupervised machine learning with yutube video\n",
      "\n",
      "================================================================================\n",
      "\n",
      "supervisor:\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "transfer_to_debug_educational_agent:\n",
      "Successfully transferred to debug_educational_agent\n",
      "\n",
      "================================================================================\n",
      "\n",
      "debug_educational_agent:\n",
      "**Supervised vs Unsupervised Machine Learning: A Clear Explanation**\n",
      "=================================================================\n",
      "\n",
      "In machine learning, we have two primary types of learning: supervised and unsupervised. Understanding the difference between these two is crucial for building accurate and effective models.\n",
      "\n",
      "**Supervised Learning**\n",
      "--------------------\n",
      "\n",
      "Supervised learning is a type of machine learning where the model is trained on labeled data. This means that the data is already annotated with the correct output, and the model learns to map inputs to outputs based on these labels.\n",
      "\n",
      "**Example:** Image classification, where the model is trained on images of dogs and cats, and the labels indicate whether the image is a dog or a cat.\n",
      "\n",
      "**How it works:**\n",
      "\n",
      "1. The model is trained on a dataset of labeled examples.\n",
      "2. The model learns to recognize patterns in the data and make predictions based on these patterns.\n",
      "3. The model is evaluated on a test dataset to measure its performance.\n",
      "\n",
      "**Unsupervised Learning**\n",
      "----------------------\n",
      "\n",
      "Unsupervised learning is a type of machine learning where the model is trained on unlabeled data. This means that the data does not have any inherent structure or meaning, and the model must discover patterns and relationships on its own.\n",
      "\n",
      "**Example:** Clustering customers based on their buying behavior, where the model groups similar customers together without any prior knowledge of their behavior.\n",
      "\n",
      "**How it works:**\n",
      "\n",
      "1. The model is trained on a dataset of unlabeled examples.\n",
      "2. The model discovers patterns and relationships in the data through clustering, dimensionality reduction, or other techniques.\n",
      "3. The model is evaluated on a test dataset to measure its performance.\n",
      "\n",
      "**Key differences:**\n",
      "\n",
      "* **Labeled vs Unlabeled Data:** Supervised learning uses labeled data, while unsupervised learning uses unlabeled data.\n",
      "* **Model Objective:** Supervised learning aims to minimize the error between predicted and actual outputs, while unsupervised learning aims to discover patterns and relationships in the data.\n",
      "* **Evaluation Metrics:** Supervised learning uses metrics such as accuracy, precision, and recall, while unsupervised learning uses metrics such as silhouette score, calinski-harabasz index, and davies-bouldin index.\n",
      "\n",
      "**Code Example:**\n",
      "```python\n",
      "# Supervised Learning Example (Image Classification)\n",
      "from tensorflow.keras.datasets import mnist\n",
      "from tensorflow.keras.models import Sequential\n",
      "from tensorflow.keras.layers import Dense, Dropout\n",
      "\n",
      "# Load MNIST dataset\n",
      "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
      "\n",
      "# Reshape and normalize data\n",
      "x_train = x_train.reshape(-1, 784)\n",
      "x_test = x_test.reshape(-1, 784)\n",
      "x_train = x_train.astype('float32') / 255\n",
      "x_test = x_test.astype('float32') / 255\n",
      "\n",
      "# Define model architecture\n",
      "model = Sequential()\n",
      "model.add(Dense(64, activation='relu', input_shape=(784,)))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(Dense(10, activation='softmax'))\n",
      "\n",
      "# Compile model\n",
      "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
      "\n",
      "# Train model\n",
      "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))\n",
      "\n",
      "# Evaluate model\n",
      "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
      "print(f'Test accuracy: {test_acc:.2f}')\n",
      "```\n",
      "\n",
      "```python\n",
      "# Unsupervised Learning Example (Clustering Customers)\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.datasets import make_blobs\n",
      "\n",
      "# Generate sample data\n",
      "X, _ = make_blobs(n_samples=100, centers=5, n_features=2, random_state=0)\n",
      "\n",
      "# Define clustering model\n",
      "kmeans = KMeans(n_clusters=5, random_state=0)\n",
      "\n",
      "# Fit model\n",
      "kmeans.fit(X)\n",
      "\n",
      "# Get cluster labels\n",
      "labels = kmeans.labels_\n",
      "\n",
      "# Print cluster labels\n",
      "print(labels)\n",
      "```\n",
      "\n",
      "**Practice Exercise:**\n",
      "\n",
      "1. Train a supervised learning model on the MNIST dataset to classify handwritten digits.\n",
      "2. Train an unsupervised learning model on the Iris dataset to cluster flowers based on their characteristics.\n",
      "\n",
      "**Learning Resources:**\n",
      "\n",
      "* \"Supervised Learning\" by Andrew Ng (Coursera)\n",
      "* \"Unsupervised Learning\" by Andrew Ng (Coursera)\n",
      "* \"Machine Learning\" by Scikit-learn (Python library)\n",
      "* \"K-Means Clustering\" by Scikit-learn (Python library)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "debug_educational_agent:\n",
      "Transferring back to supervisor\n",
      "\n",
      "================================================================================\n",
      "\n",
      "transfer_back_to_supervisor:\n",
      "Successfully transferred back to supervisor\n",
      "\n",
      "================================================================================\n",
      "\n",
      "supervisor:\n",
      "I can provide more information on supervised and unsupervised machine learning if you'd like.\n",
      "\n",
      "**Supervised Learning:**\n",
      "\n",
      "Supervised learning is a type of machine learning where the model is trained on labeled data. This means that the data is already annotated with the correct output, and the model learns to map inputs to outputs based on these labels.\n",
      "\n",
      "**Types of Supervised Learning:**\n",
      "\n",
      "1. **Classification:** The model predicts a categorical label or class.\n",
      "2. **Regression:** The model predicts a continuous output value.\n",
      "\n",
      "**Common Supervised Learning Algorithms:**\n",
      "\n",
      "1. **Linear Regression:** A linear model that predicts a continuous output value.\n",
      "2. **Logistic Regression:** A linear model that predicts a categorical label.\n",
      "3. **Decision Trees:** A tree-based model that predicts a categorical label.\n",
      "4. **Random Forest:** An ensemble model that combines multiple decision trees.\n",
      "5. **Support Vector Machines (SVMs):** A linear or non-linear model that predicts a categorical label.\n",
      "\n",
      "**Unsupervised Learning:**\n",
      "\n",
      "Unsupervised learning is a type of machine learning where the model is trained on unlabeled data. This means that the data does not have any inherent structure or meaning, and the model must discover patterns and relationships on its own.\n",
      "\n",
      "**Types of Unsupervised Learning:**\n",
      "\n",
      "1. **Clustering:** The model groups similar data points together.\n",
      "2. **Dimensionality Reduction:** The model reduces the number of features in the data.\n",
      "3. **Anomaly Detection:** The model identifies data points that are significantly different from the rest.\n",
      "\n",
      "**Common Unsupervised Learning Algorithms:**\n",
      "\n",
      "1. **K-Means Clustering:** A clustering algorithm that groups data points into clusters.\n",
      "2. **Hierarchical Clustering:** A clustering algorithm that builds a hierarchy of clusters.\n",
      "3. **Principal Component Analysis (PCA):** A dimensionality reduction algorithm that reduces the number of features.\n",
      "4. **t-Distributed Stochastic Neighbor Embedding (t-SNE):** A dimensionality reduction algorithm that reduces the number of features.\n",
      "\n",
      "**Real-World Applications:**\n",
      "\n",
      "1. **Image Classification:** Supervised learning is used to classify images into different categories.\n",
      "2. **Natural Language Processing (NLP):** Supervised learning is used to classify text into different categories.\n",
      "3. **Recommendation Systems:** Supervised learning is used to recommend products or services based on user behavior.\n",
      "4. **Anomaly Detection:** Unsupervised learning is used to detect unusual patterns in data.\n",
      "\n",
      "**Code Examples:**\n",
      "\n",
      "1. **Supervised Learning (Image Classification):**\n",
      "```python\n",
      "from tensorflow.keras.datasets import mnist\n",
      "from tensorflow.keras.models import Sequential\n",
      "from tensorflow.keras.layers import Dense, Dropout\n",
      "\n",
      "# Load MNIST dataset\n",
      "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
      "\n",
      "# Reshape and normalize data\n",
      "x_train = x_train.reshape(-1, 784)\n",
      "x_test = x_test.reshape(-1, 784)\n",
      "x_train = x_train.astype('float32') / 255\n",
      "x_test = x_test.astype('float32') / 255\n",
      "\n",
      "# Define model architecture\n",
      "model = Sequential()\n",
      "model.add(Dense(64, activation='relu', input_shape=(784,)))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(Dense(10, activation='softmax'))\n",
      "\n",
      "# Compile model\n",
      "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
      "\n",
      "# Train model\n",
      "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))\n",
      "\n",
      "# Evaluate model\n",
      "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
      "print(f'Test accuracy: {test_acc:.2f}')\n",
      "```\n",
      "\n",
      "2. **Unsupervised Learning (Clustering Customers):**\n",
      "```python\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.datasets import make_blobs\n",
      "\n",
      "# Generate sample data\n",
      "X, _ = make_blobs(n_samples=100, centers=5, n_features=2, random_state=0)\n",
      "\n",
      "# Define clustering model\n",
      "kmeans = KMeans(n_clusters=5, random_state=0)\n",
      "\n",
      "# Fit model\n",
      "kmeans.fit(X)\n",
      "\n",
      "# Get cluster labels\n",
      "labels = kmeans.labels_\n",
      "\n",
      "# Print cluster labels\n",
      "print(labels)\n",
      "```\n",
      "\n",
      "Let me know if you have any further questions or if there's anything else I can help you with!\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Suppose `result` is what you got from app.invoke(...)\n",
    "for msg in result[\"messages\"]:\n",
    "    # Check if the message has 'content'\n",
    "    if hasattr(msg, 'content'):\n",
    "        print(f\"{msg.name}:\")  # Optional: show which agent\n",
    "        print(msg.content)\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8559408d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28716fe2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "029b4432",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f9ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "None:\n",
    "Explain the difference between supervised and unsupervised machine learning with examples\n",
    "\n",
    "================================================================================\n",
    "\n",
    "supervisor:\n",
    "\n",
    "\n",
    "================================================================================\n",
    "\n",
    "transfer_to_curriculum_agent:\n",
    "Successfully transferred to curriculum_agent\n",
    "\n",
    "================================================================================\n",
    "\n",
    "curriculum_agent:\n",
    "**Supervised vs Unsupervised Machine Learning**\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables computers to learn from data without being explicitly programmed. There are two primary types of machine learning: supervised and unsupervised.\n",
    "\n",
    "**Supervised Machine Learning**\n",
    "\n",
    "In supervised machine learning, the algorithm is trained on labeled data, where the correct output is already known. The goal is to learn a mapping between input data and output labels, so the algorithm can make predictions on new, unseen data.\n",
    "\n",
    "Example:\n",
    "\n",
    "* Image classification: Train a model on a dataset of labeled images (e.g., dogs, cats, cars) to learn the features that distinguish each class.\n",
    "* Sentiment analysis: Train a model on a dataset of labeled text (e.g., positive, negative, neutral) to learn the features that indicate the sentiment of a piece of text.\n",
    "\n",
    "**Unsupervised Machine Learning**\n",
    "\n",
    "In unsupervised machine learning, the algorithm is trained on unlabeled data, and the goal is to discover patterns, relationships, or structure in the data.\n",
    "\n",
    "Example:\n",
    "\n",
    "* Clustering: Group similar data points into clusters based on their features (e.g., customer segmentation).\n",
    "* Dimensionality reduction: Reduce the number of features in a dataset while preserving the most important information (e.g., PCA).\n",
    "\n",
    "**Key differences:**\n",
    "\n",
    "* **Labeled data**: Supervised learning requires labeled data, while unsupervised learning does not.\n",
    "* **Goal**: Supervised learning aims to make predictions, while unsupervised learning aims to discover patterns or structure.\n",
    "* **Algorithmic approach**: Supervised learning typically involves regression or classification algorithms, while unsupervised learning involves clustering, dimensionality reduction, or density estimation algorithms.\n",
    "\n",
    "**YouTube Videos:**\n",
    "\n",
    "* \"Supervised vs Unsupervised Machine Learning\" by Siraj Raval (3:34 minutes)\n",
    "* \"Unsupervised Machine Learning\" by 3Blue1Brown (10:45 minutes)\n",
    "* \"Supervised vs Unsupervised Learning\" by DataCamp (4:21 minutes)\n",
    "\n",
    "**Learning Steps:**\n",
    "\n",
    "1. Understand the concept of labeled and unlabeled data.\n",
    "2. Learn the differences between supervised and unsupervised machine learning.\n",
    "3. Study the examples and applications of each type of machine learning.\n",
    "4. Practice implementing supervised and unsupervised algorithms using popular libraries like scikit-learn or TensorFlow.\n",
    "5. Experiment with real-world datasets to apply your knowledge and gain hands-on experience.\n",
    "\n",
    "================================================================================\n",
    "\n",
    "curriculum_agent:\n",
    "Transferring back to supervisor\n",
    "\n",
    "================================================================================\n",
    "\n",
    "transfer_back_to_supervisor:\n",
    "Successfully transferred back to supervisor\n",
    "\n",
    "================================================================================\n",
    "\n",
    "supervisor:\n",
    "It looks like you're ready to move on to the next topic. What would you like to explore next?\n",
    "\n",
    "================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a0377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = create_supervisor(\n",
    "    [\n",
    "        curriculum_agent, debug_agent,\n",
    "        resume_agent, unified_agent, news_agent\n",
    "    ],\n",
    "    model=hf_model,\n",
    "    prompt=\"\"\"\n",
    "You are SUPERVISOR-GUIDE, responsible for routing user queries to the appropriate specialized agent\n",
    "(curriculum, debugging, resume/cover letter, feedback, tech news) and producing a final, \n",
    "well-formatted, concise, and complete response.\n",
    "\n",
    "**Important:** For **any educational, conceptual, or curriculum-related query**, you must:\n",
    "\n",
    "1. Provide a step-by-step explanation with examples.\n",
    "2. Dynamically fetch up to 3 relevant YouTube videos using the `youtube_search` tool.\n",
    "3. Include **only valid video titles and URLs** returned by the `youtube_search` tool.\n",
    "4. If no videos are found, include this message: \"No relevant video found; refer to online resources.\"\n",
    "5. Format explanations clearly using bullet points, numbered lists, or code blocks.\n",
    "\n",
    "Follow these rules:\n",
    "\n",
    "1. **Identify intent**: Analyze the query and route it to the correct agent(s). Use multiple agents sequentially if needed.\n",
    "\n",
    "2. **Curriculum / Learning queries**:\n",
    "   - Fetch top relevant courses dynamically from websites.\n",
    "   - Attach YouTube video links using `youtube_search`.\n",
    "   - Present in **clean, point-wise format**: Course Name ‚Äì Video Link\n",
    "\n",
    "3. **Educational / Conceptual queries**:\n",
    "   - Forward to `debug_agent` or handle directly.\n",
    "   - Include step-by-step explanations and examples.\n",
    "   - Attach **YouTube videos dynamically** using `youtube_search`.\n",
    "\n",
    "4. **Debugging / Skills queries**: Forward to `debug_agent`. Include explanations, suggested fixes, examples, and exercises if relevant.\n",
    "\n",
    "5. **Resume / Cover letter queries**: Forward to `resume_agent`. Ensure output is professional, concise, and structured (HTML or readable text).\n",
    "\n",
    "6. **Feedback / Reviews**: Forward to `feedback_agent`. Responses should be friendly, motivational, and context-aware.\n",
    "\n",
    "7. **Technology News**: Forward to `news_agent`. Summarize in **point-wise format**, including trending tools or technologies. Keep it concise and actionable.\n",
    "\n",
    "8. **Formatting & Clarity**:\n",
    "   - Return **only the final output**; do not include internal agent steps.\n",
    "   - Include lists and links **only if valid**.\n",
    "   - Ensure readability: not too short, not too long.\n",
    "\n",
    "9. **Dynamic Handling**:\n",
    "   - Prefer real-time data retrieval via web search or APIs.\n",
    "   - Fall back gracefully if data is unavailable.\n",
    "\n",
    "Goal: Provide **accurate, complete, user-friendly, and visually clear responses** while coordinating all agents efficiently.\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac90ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae13a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39202114",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. No title (Unkn)\n",
    "   Authors: \n",
    "   Summary:  This research abstract is a review of recent Deep Learning advances in text summarization, an NLP task that condenses text into shorter forms while retaining meaning. It highlights the use of pointer...\n",
    "   Link: None\n",
    "\n",
    "2. No title (Unkn)\n",
    "   Authors: \n",
    "   Summary:  This research examines the performance of popular transformer-based NLP models when fine-tuned on noisy text, specifically looking at spelling mistakes and typos. The findings suggest that these mode...\n",
    "   Link: None\n",
    "\n",
    "3. No title (Unkn)\n",
    "   Authors: \n",
    "   Summary:  The abstract describes research that summarizes and examines current state-of-the-art NLP models, which have achieved success in various linguistic and semantic tasks through the Transformer architec...\n",
    "   Link: None\n",
    "\n",
    "4. No title (Unkn)\n",
    "   Authors: \n",
    "   Summary:  This study compares the performance of NLP-based models and CNN-based models in predicting biomarkers in colorectal cancer using digital pathology images. The results showed that NLP-based models, sp...\n",
    "   Link: None\n",
    "\n",
    "5. No title (Unkn)\n",
    "   Authors: \n",
    "   Summary:  The Transformer architecture and pre-trained models like BERT have significantly advanced NLP, but limitations remain in modeling certain kinds of information. This research shows that addressing the...\n",
    "   Link: None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd24c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b2094a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper 1:\n",
      "Raw Info: Published year: 2023\n",
      "Title: Divide et Impera: Multi-Transformer Architectures for Complex NLP-Tasks\n",
      "Authors: Solveig Helland, Elena Gavagnin, Alexandre de Spindler\n",
      "Abstract: The growing capabilities of transformer models pave the way for solving increasingly complex NLP tasks. A key to supporting application-specific requirements is the ability to fine-tune. However, compiling a fine-tuning dataset tailored to complex tasks is tedious and results in large datasets, limiting the ability to control transformer output. We present an approach in which complex tasks are divided into simpler subtasks. Multiple transformer models are fine-tuned to one subtask each, and lined up to accomplish the complex task. This simplifies the compilation of fine-tuning datasets and increases overall controllability. Using the example of reducing gender bias as a complex task, we demonstrate our approach and show that it performs better than using a single model.\n",
      "Summary:  This research, published in 2023, proposes a \"Divide and Conquer\" approach for complex NLP tasks using multi-transformer architectures. The authors suggest dividing complex tasks into simpler subtasks, fine-tuning individual transformer models for each subtask, and then aligning them to accomplish the complex task. This method eases the process of creating fine-tuning datasets and increases overall controllability. The paper demonstrates the approach using reducing gender bias as a complex task and shows that it outperforms using a single model.\n",
      "--------------------------------------------------------------------------------\n",
      "Paper 2:\n",
      "Raw Info: \n",
      "Published year: 2023\n",
      "Title: NLP Framework for Analysis and Classification of Construction Documentation: A Comparative Study of Transformer and Recurrent Neural Network Architectures\n",
      "Authors: Sai Kothapalli\n",
      "Abstract: The construction industry generates vast amounts of textual documentation including specifications, contracts, claims, and change orders that require extensive manual review and analysis. This paper presents a comparative study of state-of-the-art Natural Language Processing (NLP) models for automated processing of construction documents. This research evaluates four distinct approaches: traditional machine learning with TF-IDF features, LSTM-based recurrent neural networks, BERT-based transformer models, and domain-specific fine-tuned models. The dataset comprises 2,847 construction documents across four categories, with performance evaluated using accuracy, precision, recall, and F1-score metrics. Results demonstrate that domain-specific fine-tuned BERT models achieve superior performance with 94.2% accuracy for document classification and 87.8% F1-score for information extraction tasks, significantly outperforming traditional approaches. The findings provide crucial insights for implementing automated document processing systems in construction project management.\n",
      "Summary:  This research from 2\n",
      "--------------------------------------------------------------------------------\n",
      "Paper 3:\n",
      "Raw Info: \n",
      "Published year: 2024\n",
      "Title: Ensemble of vision transformer architectures for efficient Alzheimer‚Äôs Disease classification\n",
      "Authors: Noushath Shaffi, Viswan Vimbi, Mufti Mahmud\n",
      "Abstract: Transformers have dominated the landscape of Natural Language Processing (NLP) and revolutionalized generative AI applications. Vision Transformers (VT) have recently become a new state-of-the-art for computer vision applications. Motivated by the success of VTs in capturing short and long-range dependencies and their ability to handle class imbalance, this paper proposes an ensemble framework of VTs for the efficient classification of Alzheimer‚Äôs Disease (AD). The framework consists of four vanilla VTs, and ensembles formed using hard and soft-voting approaches. The proposed model was tested using two popular AD datasets: OASIS and ADNI. The ADNI dataset was employed to assess the models‚Äô efficacy under imbalanced and data-scarce conditions. The ensemble of VT saw an improvement of around 2% compared to individual models. Furthermore, the results are compared with state-of-the-art and custom-built Convolutional Neural Network (CNN) architectures and Machine Learning (ML) models under varying data conditions. The experimental results demonstrated an overall performance gain of 4.14% and 4.72% accuracy over the ML and CNN algorithms, respectively. The study has also identified specific limitations and proposes avenues for future research. The codes used in the study are made publicly available.\n",
      "Summary:  This research from 2024 proposes an ensemble framework of Vision Transformers (VTs) for efficient Alzheimer's Disease (AD) classification, showing a 2% improvement over individual models and outperforming certain CNN and ML algorithms by 4.14% and 4.72% accuracy, respectively. The ensemble model was tested using the OASIS and ADNI datasets, demonstrating robustness under imbalanced and data-scarce conditions. The code is publicly available, and the study suggests future research directions.\n",
      "--------------------------------------------------------------------------------\n",
      "Paper 4:\n",
      "Raw Info: \n",
      "Published year: 2021\n",
      "Title: The NLP Cookbook: Modern Recipes for Transformer Based Deep Learning Architectures\n",
      "Authors: Sushant Singh, A. Mahmood\n",
      "Abstract: In recent years, Natural Language Processing (NLP) models have achieved phenomena\n",
      "Summary:  The \"NLP Cookbook\" research article, published in 2021, presents modern recipes for building Transformer-based deep learning architectures for Natural Language Processing tasks. The authors, Sushant Singh and A. Mahmood, provide a comprehensive guide on the application of Transformers, discussing their strengths, limitations, and the steps required to build and train effective models. They also explore various Transformer-based architectures, such as BERT and RoBERTa, and how they have achieved state-of-the-art performance in NLP challenges. The NLP Cookbook aims to help practitioners and researchers create and customize advanced NLP models, addressing common use cases and challenges.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # -------------------------\n",
    "# # PDF Extraction Function\n",
    "# # -------------------------\n",
    "# def extract_text_from_pdf(url: str, max_pages: int = 5) -> str:\n",
    "#     try:\n",
    "#         response = requests.get(url, timeout=15)\n",
    "#         if response.status_code != 200:\n",
    "#             return \"\"\n",
    "#         pdf_file = BytesIO(response.content)\n",
    "#         reader = PdfReader(pdf_file)\n",
    "#         text = [page.extract_text() or \"\" for page in reader.pages[:max_pages]]\n",
    "#         return \"\\n\".join(text)\n",
    "#     except Exception as e:\n",
    "#         return f\"Error extracting PDF: {e}\"\n",
    "\n",
    "# # -------------------------\n",
    "# # Initialize Semantic Scholar API\n",
    "# # -------------------------\n",
    "# ss = SemanticScholarAPIWrapper(\n",
    "#     top_k_results=5,  # Number of top papers to fetch\n",
    "#     load_max_docs=5,  # Limit of loaded documents\n",
    "# )\n",
    "\n",
    "# # -------------------------\n",
    "# # Function to fetch & summarize papers\n",
    "# # -------------------------\n",
    "# def fetch_and_summarize(query: str, summarize: bool = True) -> List[Dict]:\n",
    "#     raw_results = ss.run(query)  # Returns string with paper info\n",
    "#     # Normally, you would parse JSON if you need structured data\n",
    "#     # For demonstration, we split papers by double newlines\n",
    "#     papers = raw_results.split(\"\\n\\n\")\n",
    "#     summarized_papers = []\n",
    "\n",
    "#     for paper in papers:\n",
    "#         # Optionally summarize abstract with LLM\n",
    "#         summary = \"\"\n",
    "#         if summarize and \"abstract:\" in paper.lower():\n",
    "#             prompt = f\"Summarize this research abstract in 2-3 sentences:\\n\\n{paper}\"\n",
    "#             summary = hf_model.invoke([HumanMessage(content=prompt)]).content\n",
    "#         summarized_papers.append({\n",
    "#             \"raw_info\": paper,\n",
    "#             \"summary\": summary\n",
    "#         })\n",
    "\n",
    "#     return summarized_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "87bcfcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=' The main topic of this video is Pedro Pascal\\'s career, his experiences shooting different shows like \"The Last of Us\" on HBO, \"Game of Thrones,\" and \"The Mandalorian,\" as well as his family background and early career in Chile and the United States.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 2206, 'total_tokens': 2268}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run--57002112-6597-4390-9779-a503a313ac28-0' usage_metadata={'input_tokens': 2206, 'output_tokens': 62, 'total_tokens': 2268}\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled, VideoUnavailable\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# -----------------------------\n",
    "# Initialize LLM\n",
    "# -----------------------------\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    task=\"text-generation\",\n",
    "    do_sample=False,\n",
    "    temperature=0.1\n",
    ")\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# -----------------------------\n",
    "# Prompt Template\n",
    "# -----------------------------\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant designed to answer questions about a YouTube video based on its transcript.\n",
    "Answer the user's question using ONLY the provided transcript context.\n",
    "If the information is not in the context, explicitly say \"I cannot find information about that in the video transcript.\"\n",
    "\n",
    "Transcript:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=['context', 'question'])\n",
    "\n",
    "# -----------------------------\n",
    "# Transcript Fetcher\n",
    "# -----------------------------\n",
    "def get_transcript(video_id: str):\n",
    "    \"\"\"Fetch transcript safely for old and new versions of youtube_transcript_api.\"\"\"\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi().fetch(video_id, languages=[\"hi\"])\n",
    "    except NoTranscriptFound:\n",
    "        try:\n",
    "            transcript_list = YouTubeTranscriptApi().fetch(video_id, languages=[\"en\"])\n",
    "        except NoTranscriptFound:\n",
    "            return None, \"No transcript available in Hindi or English.\"\n",
    "    except (TranscriptsDisabled, VideoUnavailable) as e:\n",
    "        return None, str(e)\n",
    "    except Exception as e:\n",
    "        return None, f\"Unexpected error: {str(e)}\"\n",
    "\n",
    "    # Handle both dicts and FetchedTranscriptSnippet objects\n",
    "    texts = []\n",
    "    for snippet in transcript_list:\n",
    "        if isinstance(snippet, dict):\n",
    "            texts.append(snippet.get(\"text\", \"\"))\n",
    "        else:\n",
    "            # FetchedTranscriptSnippet object\n",
    "            texts.append(getattr(snippet, \"text\", \"\"))\n",
    "\n",
    "    transcript = \" \".join(texts)\n",
    "    return transcript, None\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main YouTube QA / Summarizer\n",
    "# -----------------------------\n",
    "def youtube_qa(video_url: str, question: str):\n",
    "    \"\"\"Given a YouTube URL and question, return answer based on transcript.\"\"\"\n",
    "    try:\n",
    "        video_id = video_url.split(\"v=\")[-1].split(\"&\")[0]  # Extract only the video ID\n",
    "        transcript, error = get_transcript(video_id)\n",
    "        if error:\n",
    "            return error\n",
    "\n",
    "        rag_runnable = (\n",
    "            {\"context\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | model\n",
    "        )\n",
    "        answer = rag_runnable.invoke({\"context\": transcript, \"question\": question})\n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "video_url = \"https://www.youtube.com/watch?v=QsYGlZkevEg\"\n",
    "question = \"What is the main topic of this video?\"\n",
    "print(youtube_qa(video_url, question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c29fd94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806dceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
